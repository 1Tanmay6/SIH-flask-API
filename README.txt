run 1: pip3 install -r requirements.txt
run 2: main.py

NOTE 1: LLAMA model is not in the github repo so the '/answer' route will not work if you want to make it work download the 'llama-2-7b-chat.ggmlv3.q8_0.bin' from onedrive and paste it in the folder same as main_flask.py
NOTE 2: Don't use Student network or any other university wifi api wont work.
NOTE 3: Use the link which is dynamically generated in terminal like this 'Use this: https://<something>.trycloudflare.com'

Version: 2.0.0
